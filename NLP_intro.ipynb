{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc75a6ef-21f4-484a-bd5d-be361d928066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Juan\\\\nlp_intro'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced12bb7-87f3-48ff-a737-1e3fa51d5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:\\\\Jupyter projects\\\\nlp_intro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c7eb14-90a5-48ac-94ac-4b97d40bbaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Jupyter projects\\\\nlp_intro'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7fbacb4-ab86-45a2-9f95-aa6faf3cebd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 3060 (UUID: GPU-e8861a5c-89dd-5ee2-06b2-d3bca4ee7bc6)\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8441e5a7-141e-45b0-b351-1133b3b91e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-10-31 20:20:54--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10246 (10K) [text/plain]\n",
      "Saving to: 'helper_functions.py.3'\n",
      "\n",
      "     0K ..........                                            100% 3.33M=0.003s\n",
      "\n",
      "2022-10-31 20:20:54 (3.33 MB/s) - 'helper_functions.py.3' saved [10246/10246]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download helper functions script\n",
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a604ebd5-a459-4e59-82f2-8aa3b51f6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import series of helper functions for the notebook\n",
    "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "721900ea-388d-449c-b28c-837d42f365de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-10-31 20:21:03--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 66.102.1.128, 142.251.5.128, 64.233.167.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|66.102.1.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 607343 (593K) [application/zip]\n",
      "Saving to: 'nlp_getting_started.zip.4'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  8% 1.31M 0s\n",
      "    50K .......... .......... .......... .......... .......... 16% 2.61M 0s\n",
      "   100K .......... .......... .......... .......... .......... 25% 5.51M 0s\n",
      "   150K .......... .......... .......... .......... .......... 33% 8.73M 0s\n",
      "   200K .......... .......... .......... .......... .......... 42% 7.26M 0s\n",
      "   250K .......... .......... .......... .......... .......... 50% 10.4M 0s\n",
      "   300K .......... .......... .......... .......... .......... 59% 15.0M 0s\n",
      "   350K .......... .......... .......... .......... .......... 67% 12.1M 0s\n",
      "   400K .......... .......... .......... .......... .......... 75% 24.1M 0s\n",
      "   450K .......... .......... .......... .......... .......... 84% 4.48M 0s\n",
      "   500K .......... .......... .......... .......... .......... 92% 8.83M 0s\n",
      "   550K .......... .......... .......... .......... ...       100% 12.2M=0.1s\n",
      "\n",
      "2022-10-31 20:21:03 (5.21 MB/s) - 'nlp_getting_started.zip.4' saved [607343/607343]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download data (same as from Kaggle)\n",
    "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
    "\n",
    "# Unzip data\n",
    "unzip_data(\"nlp_getting_started.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37069212-a601-4fad-b3c6-200ff09518cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn .csv files into pandas DataFrame's\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4de20eab-5987-4475-8727-4cf3b4d74a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41db42b8-cb17-485a-80d8-d98dcab61ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The test data doesn't have a target (that's what we'd try to predict)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00ca1756-1f4e-406c-b338-8a605ea5abb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many examples of each class?\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ad19921-f72d-4a2e-adf8-dcb2cc175198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 7613\n",
      "Total test samples: 3263\n",
      "Total samples: 10876\n"
     ]
    }
   ],
   "source": [
    "# How many samples total?\n",
    "print(f\"Total training samples: {len(train_df)}\")\n",
    "print(f\"Total test samples: {len(test_df)}\")\n",
    "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33d97aaa-4cd0-4a11-ae90-4d028c91af90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "HAPPY 24 TWISTER!!! Thank you for all the laughs sticking by my side no matter what and also forÛ_ https://t.co/ttq9IlHp8W\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Kenya News (Chelsea talisman Eden Hazard keen to match Cristiano Ronaldo and Lionel Messi.)  Mipasho http://t.co/LxvLqVbc8r\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "When you lowkey already know you're gonna drown in school this year :) http://t.co/aCMrm833zq\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Refugio oil spill may have been costlier bigger than projected http://t.co/lzob8qOH1B\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "WHY THE DEEP ROADS THO HAHAHAHA IM SO TRAUMATISED BY THE DEEP ROADS LOLOL\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize some random training examples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23ca785d-d9cb-409b-ac78-92285061b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
    "                                                                            random_state=42) # random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc9ecb24-abc3-4174-9717-f5533fef5b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 10 training sentences and their labels\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b49ca741-a54a-42af-b1f8-b5ce5fdf2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94b149dc-539b-4bec-8385-08d9d98f5769",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = TextVectorization(max_tokens=None,\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                    split=\"whitespace\",\n",
    "                                    ngrams=None,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9ed86d0-b66d-40cd-a660-f172a413cf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find average number of tokens/words in training tweets\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e24040e-0a8c-4da4-a5b9-489b69d5532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_length = 10000\n",
    "max_length = 15\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode='int',\n",
    "                                    output_sequence_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bd30c6a-e0a5-4053-b654-0d30917edf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbb8b9fc-0981-4932-84cf-41c21b95d303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create sample sentence\n",
    "sample_sentence = \"There's a flood in my street!\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1e05fae-11ac-459b-b1cc-91ef583152cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "11 puncture wounds      \n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 968, 4834,  523,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0]], dtype=int64)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choose random\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nVectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed4630ca-8941-4935-8d1b-4a4164a510ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "#Get unique words in vocab\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5] #5 most common tokens\n",
    "bottom_5_words = words_in_vocab[-5:]# 5 least common tokens\n",
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"Top 5 most common words: {top_5_words}\") \n",
    "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07cf86f0-79d9-408f-80be-fbd5fc5880d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x26929034280>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                             output_dim=128,\n",
    "                             embeddings_initializer='uniform',\n",
    "                             input_length=max_length,\n",
    "                             name='embedding_1'\n",
    "                            )\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cf6efa1-3e23-4444-8a94-c1476c728ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "#iphone #twist Ultimate #preparedness library: http://t.co/ksgmY0D0Mx Prepare Yourself For Any Catastrophe. Ov http://t.co/MZK0PFogI7      \n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[ 0.0010178 , -0.03880132, -0.01127563, ...,  0.00825617,\n",
       "         -0.04927752, -0.00497234],\n",
       "        [ 0.04587283,  0.01872038,  0.00884764, ..., -0.03619492,\n",
       "         -0.02061249, -0.03794064],\n",
       "        [ 0.02808792,  0.04362499,  0.03932795, ...,  0.04685874,\n",
       "         -0.02181524,  0.03074307],\n",
       "        ...,\n",
       "        [ 0.03977952, -0.03782602, -0.03646283, ...,  0.00236253,\n",
       "          0.03332629,  0.02803668],\n",
       "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
       "          0.00912381, -0.00024097],\n",
       "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
       "          0.00912381, -0.00024097]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nEmbedded version:\")\n",
    "\n",
    "#embed random sentence\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f60aabbd-abaa-4bb2-8a0f-a19f08fcdf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([ 1.01779774e-03, -3.88013236e-02, -1.12756267e-02, -1.47443786e-02,\n",
       "       -4.28895019e-02,  4.45820428e-02,  4.73705269e-02, -3.24172005e-02,\n",
       "        3.73673923e-02, -4.16718945e-02, -3.71053107e-02, -3.83436792e-02,\n",
       "       -4.86301780e-02,  1.65980719e-02, -2.02744957e-02, -1.90378316e-02,\n",
       "        9.81440395e-03,  1.90672539e-02, -2.13007331e-02,  1.58449449e-02,\n",
       "        2.27000751e-02,  3.99191119e-02, -1.29036903e-02,  1.07263550e-02,\n",
       "       -7.89596885e-03, -3.22480947e-02, -4.24733534e-02,  9.54698399e-03,\n",
       "        2.29340680e-02, -1.60842538e-02, -1.10437050e-02, -3.93310189e-02,\n",
       "       -1.38020627e-02,  2.86242999e-02, -3.01071890e-02,  2.18748488e-02,\n",
       "        2.90810727e-02, -3.30815911e-02, -9.76644456e-04,  1.91785432e-02,\n",
       "       -2.00281385e-02, -4.96787205e-02,  6.71118498e-03, -2.38791108e-05,\n",
       "        6.76850230e-03, -1.10270754e-02,  2.22495832e-02, -3.46133821e-02,\n",
       "       -3.67922783e-02, -1.49189830e-02, -2.82469280e-02, -6.92985952e-04,\n",
       "       -4.24017571e-02,  3.38771008e-02, -2.69105565e-02,  5.64832613e-03,\n",
       "        7.75212049e-03,  1.78530477e-02, -2.59840973e-02,  4.94168065e-02,\n",
       "        3.85443009e-02, -1.64137594e-02, -4.32423726e-02,  3.23186852e-02,\n",
       "       -3.92050371e-02,  2.07420476e-02,  1.65701993e-02, -2.25553643e-02,\n",
       "       -8.28659534e-03,  3.31082083e-02, -3.91948000e-02,  1.39915608e-02,\n",
       "       -3.37790996e-02, -1.11392140e-02, -3.29407007e-02,  3.35288756e-02,\n",
       "       -3.85190733e-02, -1.58288702e-02, -2.01509837e-02, -4.76366058e-02,\n",
       "       -3.60407457e-02,  1.02051981e-02,  2.28382833e-02, -8.82110745e-03,\n",
       "        4.21282537e-02,  2.46555321e-02, -4.37369347e-02, -1.86034292e-03,\n",
       "        4.53601740e-02,  1.52087323e-02,  3.59508432e-02,  1.66678168e-02,\n",
       "       -3.50067392e-02, -1.05119720e-02, -3.16741243e-02,  5.81145287e-03,\n",
       "        1.26063712e-02, -1.33453682e-03, -4.21190038e-02, -7.31359795e-03,\n",
       "        4.44277637e-02, -2.32102033e-02,  3.21624763e-02, -2.79599912e-02,\n",
       "        7.89005682e-03, -3.53187807e-02, -4.06276099e-02,  2.12258957e-02,\n",
       "       -4.83945273e-02, -3.61381061e-02,  3.68868001e-02,  4.36014868e-02,\n",
       "       -2.81201843e-02,  4.96932976e-02,  1.74337067e-02, -3.77277285e-03,\n",
       "        4.80571128e-02, -4.96393330e-02, -1.00437775e-02,  2.27303766e-02,\n",
       "        1.35106929e-02, -4.23890352e-03, -4.95855324e-02, -4.77856398e-03,\n",
       "       -2.90282853e-02,  8.25617462e-03, -4.92775217e-02, -4.97233868e-03],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out a single token's embedding\n",
    "sample_embed[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35ff83bc-7e2d-4ef8-be41-c427ae0b7e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#create tokenization and modelling pipeline\n",
    "\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06d78448-c938-4d40-814d-27b241bc0cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 79.27%\n"
     ]
    }
   ],
   "source": [
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8855eb11-dd1c-417c-9f22-ba0aaeb48560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8b7a292-8fd3-4442-a6eb-f1c6a021de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "  \n",
    "    Args:\n",
    "    -----\n",
    "    y_true = true labels in the form of a 1D array\n",
    "    y_pred = predicted labels in the form of a 1D array\n",
    "  \n",
    "    Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "    \"\"\"\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    \n",
    "    # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\"accuracy\": model_accuracy,\n",
    "                    \"precision\": model_precision,\n",
    "                    \"recall\": model_recall,\n",
    "                    \"f1\": model_f1}\n",
    "    \n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9582e90d-2763-435b-b1d6-cc23db23f486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b32762ce-87aa-4ce4-a21c-02390be1d18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 1\n",
    "\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f510e280-9e54-4242-b31c-ec1cde6e99e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1, ), dtype='string') # inputs are 1D strings\n",
    "x = text_vectorizer(inputs) # text input into numbers\n",
    "x = embedding(x) # create embedding of numerized numbers\n",
    "x = layers.GlobalAveragePooling1D()(x) # \n",
    "\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model_1 = tf.keras.Model(inputs, outputs, name='model_1_dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb4a3cde-612b-4e28-b2b4-45b9c682abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af581f62-dce9-45a6-9d3a-8b6c0e802ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2dc9a4c-b9a7-47ae-8dd5-e07fa70bbc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/simple_dense_model/20221031-202106\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 6ms/step - loss: 0.6094 - accuracy: 0.6916 - val_loss: 0.5357 - val_accuracy: 0.7572\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.4410 - accuracy: 0.8189 - val_loss: 0.4691 - val_accuracy: 0.7848\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.3463 - accuracy: 0.8605 - val_loss: 0.4590 - val_accuracy: 0.7900\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.2848 - accuracy: 0.8923 - val_loss: 0.4641 - val_accuracy: 0.7927\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.2380 - accuracy: 0.9118 - val_loss: 0.4767 - val_accuracy: 0.7874\n"
     ]
    }
   ],
   "source": [
    "model_1_history = model_1.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                    experiment_name=\"simple_dense_model\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f00e4b0b-b5d0-40fe-b374-6fbc48f586dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4766846001148224, 0.787401556968689]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results\n",
    "model_1.evaluate(val_sentences, val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e513f3d2-fc38-4854-90cd-081b0d0e03f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding_1/embeddings:0' shape=(10000, 128) dtype=float32, numpy=\n",
       " array([[ 0.00073163,  0.01504798, -0.03425454, ..., -0.0440354 ,\n",
       "         -0.01042281,  0.01876437],\n",
       "        [ 0.04135862, -0.03945084, -0.0381194 , ...,  0.00464737,\n",
       "          0.03163552,  0.029283  ],\n",
       "        [ 0.00684032,  0.05363132, -0.00241555, ..., -0.07082176,\n",
       "         -0.04750706,  0.01448254],\n",
       "        ...,\n",
       "        [-0.03301444, -0.0052493 , -0.04209725, ...,  0.02028764,\n",
       "          0.00308807,  0.02215792],\n",
       "        [ 0.00692343,  0.05942352, -0.01975194, ..., -0.06199061,\n",
       "         -0.01018393,  0.03510419],\n",
       "        [-0.0372346 ,  0.06267187, -0.07451147, ..., -0.02367217,\n",
       "         -0.0864333 ,  0.01742155]], dtype=float32)>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d49cc94-72aa-40c1-8388-59f1dd370423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
    "print(embed_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6e0505a-1029-42d7-94d2-301e6ea6d65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4048821 ],\n",
       "       [0.7443312 ],\n",
       "       [0.997895  ],\n",
       "       [0.10889999],\n",
       "       [0.11143529],\n",
       "       [0.93556094],\n",
       "       [0.9134595 ],\n",
       "       [0.9925345 ],\n",
       "       [0.97156817],\n",
       "       [0.26570338]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions (these come back in the form of probabilities)\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs[:10] # only print out the first 10 prediction probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ce85c3f-5c2c-44c3-9ed6-826d8420e50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn prediction probabilities into single-dimension tensor of floats\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n",
    "model_1_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6dff6f2f-c520-4f8b-b5fd-00b981731811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.74015748031496,\n",
       " 'precision': 0.7914920592553047,\n",
       " 'recall': 0.7874015748031497,\n",
       " 'f1': 0.7846966492209201}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 metrics\n",
    "model_1_results = calculate_results(y_true=val_labels, \n",
    "                                    y_pred=model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c47e7016-6405-44a7-8cdd-8edb45f3f5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is our simple Keras model better than our baseline model?\n",
    "import numpy as np\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "336accc2-83ab-44bb-927c-76a097ccd3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 78.74, Difference: -0.52\n",
      "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
      "Baseline recall: 0.79, New recall: 0.79, Difference: -0.01\n",
      "Baseline f1: 0.79, New f1: 0.78, Difference: -0.00\n"
     ]
    }
   ],
   "source": [
    "# Create a helper function to compare our baseline results to new model results\n",
    "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
    "    for key, value in baseline_results.items():\n",
    "        print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
    "\n",
    "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
    "                                new_model_results=model_1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "986dd6a1-9aae-4407-a9e3-38639fa14325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "723f291c-b4c5-4ed2-a318-07aed355c5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "420e577e-3bda-4f4d-833e-d7e0b8cf1674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "# Get the weight matrix of embedding layer \n",
    "# (these are the numerical patterns between the text in the training dataset the model has learned)\n",
    "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
    "print(embed_weights.shape) # same size as vocab size and embedding_dim (each word is a embedding_dim size vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b391129-7b32-4cab-a7e6-5954e879f2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer='uniform',\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_2\"\n",
    "                                    )\n",
    "\n",
    "inputs = layers.Input(shape=(1, ), dtype='string')\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_2_embedding(x)\n",
    "print(x.shape)\n",
    "x = layers.LSTM(64)(x)\n",
    "print(x.shape)\n",
    "outputs=layers.Dense(1, activation = 'sigmoid')(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6c9b757-ca0c-4aa9-8aec-eb010014266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b088b4b2-97dd-40a8-addc-a77ec9173d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a367b5ce-fd56-44e5-9e9f-6a3a382af71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/LSTM/20221031-202115\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 4s 9ms/step - loss: 0.5100 - accuracy: 0.7416 - val_loss: 0.4566 - val_accuracy: 0.7835\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.3175 - accuracy: 0.8717 - val_loss: 0.5138 - val_accuracy: 0.7756\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.2201 - accuracy: 0.9152 - val_loss: 0.5858 - val_accuracy: 0.7677\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1556 - accuracy: 0.9428 - val_loss: 0.6041 - val_accuracy: 0.7743\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1076 - accuracy: 0.9594 - val_loss: 0.8745 - val_accuracy: 0.7507\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model_2_history = model_2.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
    "                                                                     \"LSTM\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8d81c42-5e79-47dd-8268-8892be869bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[0.00714374],\n",
       "        [0.7874937 ],\n",
       "        [0.99963737],\n",
       "        [0.05692937],\n",
       "        [0.00258346],\n",
       "        [0.9996232 ],\n",
       "        [0.9216303 ],\n",
       "        [0.99979883],\n",
       "        [0.999495  ],\n",
       "        [0.6644871 ]], dtype=float32))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation dataset\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs.shape, model_2_pred_probs[:10] # view the first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9be5faf-28dc-440d-9084-655b4c838c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round out predictions and reduce to 1-dimensional array\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14f68349-af93-4d89-85a8-bd1d271df199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.06561679790026,\n",
       " 'precision': 0.7510077975908164,\n",
       " 'recall': 0.7506561679790026,\n",
       " 'f1': 0.7489268622514025}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Calculate LSTM model results\n",
    "model_2_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6bc31e7-e627-46cc-bfe1-2bb3c18f0161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 75.07, Difference: -4.20\n",
      "Baseline precision: 0.81, New precision: 0.75, Difference: -0.06\n",
      "Baseline recall: 0.79, New recall: 0.75, Difference: -0.04\n",
      "Baseline f1: 0.79, New f1: 0.75, Difference: -0.04\n"
     ]
    }
   ],
   "source": [
    "compare_baseline_to_new_results(baseline_results, model_2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "77797f51-22b0-455e-ba14-2463ebd05729",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer='uniform',\n",
    "                                     input_length=max_length,\n",
    "                                     name='embedding_3'\n",
    "                                     )\n",
    "\n",
    "inputs = layers.Input(shape=(1, ), dtype='string')\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_3_embedding(x)\n",
    "x = layers.GRU(64)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cebacf93-5f7c-4878-9ee7-882529a06145",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(loss=\"binary_crossentropy\",\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=['accuracy']\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9d0a764-f3af-427b-8214-42b42e96c952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,317,313\n",
      "Trainable params: 1,317,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3d4ffdfd-2cf3-4a79-917b-3031202faf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/GRU/20221031-202126\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 8ms/step - loss: 0.5242 - accuracy: 0.7314 - val_loss: 0.4553 - val_accuracy: 0.7769\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.3195 - accuracy: 0.8695 - val_loss: 0.4937 - val_accuracy: 0.7808\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.2197 - accuracy: 0.9181 - val_loss: 0.5607 - val_accuracy: 0.7743\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.1599 - accuracy: 0.9441 - val_loss: 0.6220 - val_accuracy: 0.7782\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1221 - accuracy: 0.9584 - val_loss: 0.6205 - val_accuracy: 0.7677\n"
     ]
    }
   ],
   "source": [
    "model_3_history = model_3.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5, \n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0d765499-a723-4925-a17d-6359625eb45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[0.3331606 ],\n",
       "        [0.87741786],\n",
       "        [0.9980248 ],\n",
       "        [0.11560916],\n",
       "        [0.01236071],\n",
       "        [0.9925644 ],\n",
       "        [0.62147355],\n",
       "        [0.99813336],\n",
       "        [0.9982374 ],\n",
       "        [0.50195044]], dtype=float32))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation data\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs.shape, model_3_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "49c9f2ba-fb70-4293-a241-8d82b17ae233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to prediction classes\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9bd8932a-70a9-4233-8921-f3a9b1b5d32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.77165354330708,\n",
       " 'precision': 0.7675450859410361,\n",
       " 'recall': 0.7677165354330708,\n",
       " 'f1': 0.7667932666650168}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcuate model_3 results\n",
    "model_3_results = calculate_results(y_true=val_labels, \n",
    "                                    y_pred=model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "33c8b48d-814d-420f-9958-faf81d86df66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 76.77, Difference: -2.49\n",
      "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
      "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Compare to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_3_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b0e3d92f-7910-42d7-8afd-93f1aa918d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                    output_dim=128,\n",
    "                                    embeddings_initializer='uniform',\n",
    "                                    input_length=max_length,\n",
    "                                    name='embedding_4')\n",
    "\n",
    "inputs = layers.Input(shape=(1, ), dtype='string')\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_4_embedding(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name='model_4_Bidirectional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2707f48f-8f50-4c69-a841-6d90e414e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy']\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e5ec5b93-1702-4808-b53a-d712db3d34b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_Bidirectional\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,378,945\n",
      "Trainable params: 1,378,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3830c75d-83e6-45c8-ab46-8ee9c6326b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20221031-202135\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 14ms/step - loss: 0.5093 - accuracy: 0.7481 - val_loss: 0.4606 - val_accuracy: 0.7795\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.3135 - accuracy: 0.8708 - val_loss: 0.5144 - val_accuracy: 0.7690\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.2150 - accuracy: 0.9178 - val_loss: 0.5626 - val_accuracy: 0.7677\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.1523 - accuracy: 0.9469 - val_loss: 0.6365 - val_accuracy: 0.7769\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1083 - accuracy: 0.9639 - val_loss: 0.6510 - val_accuracy: 0.7664\n"
     ]
    }
   ],
   "source": [
    "model_4_history = model_4.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b04c8330-7cdf-457e-9c6f-a0df9df46181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03997265],\n",
       "       [0.82793885],\n",
       "       [0.9984213 ],\n",
       "       [0.13520303],\n",
       "       [0.00311086],\n",
       "       [0.99219877],\n",
       "       [0.9553587 ],\n",
       "       [0.99945587],\n",
       "       [0.998982  ],\n",
       "       [0.28128412]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "07ce30a8-1baa-48b0-854d-3c7e18bb15a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3cb1a26b-47c5-4d40-b7b2-b7aac88ecdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.64041994750657,\n",
       " 'precision': 0.7665895370389821,\n",
       " 'recall': 0.7664041994750657,\n",
       " 'f1': 0.7651213533864446}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_results = calculate_results(val_labels, model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8cc5ac9c-622e-470f-ab55-67148dabc736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 76.64, Difference: -2.62\n",
      "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.03\n",
      "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
     ]
    }
   ],
   "source": [
    "compare_baseline_to_new_results(baseline_results, model_4_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "84e915b4-7297-407c-a903-2b7baea3eef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"]))\n",
    "conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation='relu')\n",
    "conv_1d_output = conv_1d(embedding_test)\n",
    "max_pool = layers.GlobalMaxPool1D()\n",
    "max_pool_output = max_pool(conv_1d_output)\n",
    "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f70e59fe-5acd-4efa-b3cc-e3fbcd2deb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       " array([[[ 0.02534913, -0.03109058,  0.00285616, ..., -0.00783161,\n",
       "          -0.02685578, -0.04434132],\n",
       "         [-0.0658626 ,  0.09451492, -0.01477603, ..., -0.00657782,\n",
       "          -0.04238789,  0.07777893],\n",
       "         [-0.04803652, -0.00709756, -0.02330892, ..., -0.01807332,\n",
       "           0.02351034,  0.02676385],\n",
       "         ...,\n",
       "         [ 0.00073163,  0.01504798, -0.03425454, ..., -0.0440354 ,\n",
       "          -0.01042281,  0.01876437],\n",
       "         [ 0.00073163,  0.01504798, -0.03425454, ..., -0.0440354 ,\n",
       "          -0.01042281,  0.01876437],\n",
       "         [ 0.00073163,  0.01504798, -0.03425454, ..., -0.0440354 ,\n",
       "          -0.01042281,  0.01876437]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
       " array([[[0.08324983, 0.00648714, 0.        , 0.03983572, 0.        ,\n",
       "          0.01144416, 0.0041625 , 0.02288389, 0.        , 0.00900978,\n",
       "          0.        , 0.        , 0.03401771, 0.06408276, 0.08103722,\n",
       "          0.00409015, 0.01579617, 0.        , 0.07930177, 0.        ,\n",
       "          0.        , 0.        , 0.14525086, 0.        , 0.        ,\n",
       "          0.        , 0.03682078, 0.06534284, 0.        , 0.        ,\n",
       "          0.05094624, 0.        ],\n",
       "         [0.        , 0.05387186, 0.        , 0.11491335, 0.        ,\n",
       "          0.        , 0.16237082, 0.        , 0.        , 0.00171252,\n",
       "          0.14336711, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.01197934, 0.        , 0.        , 0.13551371, 0.0040106 ,\n",
       "          0.10309825, 0.09445542, 0.08390296, 0.        , 0.04213034,\n",
       "          0.04487597, 0.0656046 , 0.        , 0.02272683, 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.03683226, 0.04895764, 0.        , 0.15324754, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.04650314, 0.00496457, 0.07349403, 0.01608642,\n",
       "          0.        , 0.02779122, 0.        , 0.08080561, 0.01403175,\n",
       "          0.        , 0.03768813, 0.10382783, 0.        , 0.03361665,\n",
       "          0.        , 0.02577607, 0.00140356, 0.        , 0.        ,\n",
       "          0.03211498, 0.        ],\n",
       "         [0.00887821, 0.10450975, 0.        , 0.06974537, 0.02328688,\n",
       "          0.        , 0.04052209, 0.        , 0.        , 0.02733763,\n",
       "          0.08674344, 0.        , 0.        , 0.06129853, 0.02007268,\n",
       "          0.        , 0.        , 0.        , 0.03364265, 0.        ,\n",
       "          0.04525332, 0.05219701, 0.06375708, 0.        , 0.        ,\n",
       "          0.00774409, 0.0027347 , 0.        , 0.        , 0.00499634,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.02369068, 0.        , 0.0582762 , 0.05297641,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.01719719, 0.0293682 , 0.00466103, 0.06879887, 0.01944806,\n",
       "          0.01585531, 0.01294544, 0.        , 0.0686653 , 0.        ,\n",
       "          0.00623766, 0.03514048, 0.02407534, 0.        , 0.05979818,\n",
       "          0.        , 0.01170144, 0.        , 0.        , 0.        ,\n",
       "          0.04444929, 0.        ],\n",
       "         [0.03544863, 0.        , 0.        , 0.05054975, 0.06105437,\n",
       "          0.        , 0.0099743 , 0.01403009, 0.        , 0.01680727,\n",
       "          0.03148508, 0.03889386, 0.        , 0.07710679, 0.00590969,\n",
       "          0.        , 0.00263032, 0.        , 0.08935824, 0.        ,\n",
       "          0.        , 0.05331147, 0.05227952, 0.        , 0.06658387,\n",
       "          0.01881708, 0.02448699, 0.        , 0.        , 0.        ,\n",
       "          0.02008457, 0.        ],\n",
       "         [0.03544863, 0.        , 0.        , 0.05054974, 0.06105437,\n",
       "          0.        , 0.0099743 , 0.0140301 , 0.        , 0.01680727,\n",
       "          0.03148507, 0.03889387, 0.        , 0.0771068 , 0.0059097 ,\n",
       "          0.        , 0.00263033, 0.        , 0.08935823, 0.        ,\n",
       "          0.        , 0.05331147, 0.05227952, 0.        , 0.06658387,\n",
       "          0.01881707, 0.02448698, 0.        , 0.        , 0.        ,\n",
       "          0.02008458, 0.        ],\n",
       "         [0.03544864, 0.        , 0.        , 0.05054974, 0.06105438,\n",
       "          0.        , 0.00997429, 0.0140301 , 0.        , 0.01680727,\n",
       "          0.03148508, 0.03889387, 0.        , 0.07710679, 0.0059097 ,\n",
       "          0.        , 0.00263034, 0.        , 0.08935824, 0.        ,\n",
       "          0.        , 0.05331148, 0.05227952, 0.        , 0.06658386,\n",
       "          0.01881707, 0.02448698, 0.        , 0.        , 0.        ,\n",
       "          0.02008458, 0.        ],\n",
       "         [0.03544864, 0.        , 0.        , 0.05054973, 0.06105438,\n",
       "          0.        , 0.0099743 , 0.0140301 , 0.        , 0.01680727,\n",
       "          0.03148507, 0.03889386, 0.        , 0.0771068 , 0.0059097 ,\n",
       "          0.        , 0.00263033, 0.        , 0.08935824, 0.        ,\n",
       "          0.        , 0.05331147, 0.05227954, 0.        , 0.06658389,\n",
       "          0.01881708, 0.02448698, 0.        , 0.        , 0.        ,\n",
       "          0.02008457, 0.        ],\n",
       "         [0.03544864, 0.        , 0.        , 0.05054975, 0.06105437,\n",
       "          0.        , 0.0099743 , 0.0140301 , 0.        , 0.01680727,\n",
       "          0.03148508, 0.03889387, 0.        , 0.07710679, 0.00590969,\n",
       "          0.        , 0.00263033, 0.        , 0.08935824, 0.        ,\n",
       "          0.        , 0.05331147, 0.05227952, 0.        , 0.06658388,\n",
       "          0.01881708, 0.02448698, 0.        , 0.        , 0.        ,\n",
       "          0.02008456, 0.        ],\n",
       "         [0.03544864, 0.        , 0.        , 0.05054974, 0.06105438,\n",
       "          0.        , 0.00997429, 0.0140301 , 0.        , 0.01680727,\n",
       "          0.03148508, 0.03889386, 0.        , 0.07710679, 0.0059097 ,\n",
       "          0.        , 0.00263032, 0.        , 0.08935824, 0.        ,\n",
       "          0.        , 0.05331148, 0.05227953, 0.        , 0.06658387,\n",
       "          0.01881707, 0.02448698, 0.        , 0.        , 0.        ,\n",
       "          0.02008457, 0.        ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       " array([[0.08324983, 0.10450975, 0.        , 0.15324754, 0.06105438,\n",
       "         0.01144416, 0.16237082, 0.02288389, 0.        , 0.02733763,\n",
       "         0.14336711, 0.04650314, 0.03401771, 0.0771068 , 0.08103722,\n",
       "         0.01585531, 0.02779122, 0.        , 0.13551371, 0.01403175,\n",
       "         0.10309825, 0.09445542, 0.14525086, 0.        , 0.06658389,\n",
       "         0.04487597, 0.0656046 , 0.06534284, 0.02272683, 0.00499634,\n",
       "         0.05094624, 0.        ]], dtype=float32)>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the outputs of each layer\n",
    "embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "88d14a18-88b6-467e-a178-11489a0407c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_Conv1D\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 11, 32)            20512     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 32)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,300,545\n",
      "Trainable params: 1,300,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer='uniform',\n",
    "                                     input_length=max_length,\n",
    "                                     name='embedding_5')\n",
    "\n",
    "inputs = layers.Input(shape=(1, ), dtype='string')\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_5_embedding(x)\n",
    "x = layers.Conv1D(filters=32, kernel_size=5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name='model_5_Conv1D')\n",
    "\n",
    "model_5.compile(loss='binary_crossentropy',\n",
    "                optimizer='Adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_5.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2e09e1d7-ea38-466f-81d3-7293e9e22e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/Conv1D/20221031-202151\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.5654 - accuracy: 0.7152 - val_loss: 0.4729 - val_accuracy: 0.7769\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.3382 - accuracy: 0.8626 - val_loss: 0.4748 - val_accuracy: 0.7795\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.2071 - accuracy: 0.9231 - val_loss: 0.5423 - val_accuracy: 0.7664\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.1307 - accuracy: 0.9574 - val_loss: 0.6155 - val_accuracy: 0.7743\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.0934 - accuracy: 0.9695 - val_loss: 0.6714 - val_accuracy: 0.7848\n"
     ]
    }
   ],
   "source": [
    "model_5_history = model_5.fit(train_sentences,\n",
    "                             train_labels,\n",
    "                             epochs=5,\n",
    "                             validation_data=(val_sentences, val_labels),\n",
    "                             callbacks=[create_tensorboard_callback(SAVE_DIR, 'Conv1D')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8a063330-8ad2-4780-8c14-0570f17d7c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23463732],\n",
       "       [0.74668884],\n",
       "       [0.9992914 ],\n",
       "       [0.04693327],\n",
       "       [0.01458224]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_pred_probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b208f0a1-eb46-437c-94c6-fae1b4e3e8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 1., 1., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1b4cd4b8-d70d-48a8-8775-991825ba618d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.4776902887139,\n",
       " 'precision': 0.789165199286798,\n",
       " 'recall': 0.7847769028871391,\n",
       " 'f1': 0.7818959205825942}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_5_preds)\n",
    "\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "083ed313-5b4a-4600-9a3d-21aef9c724bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 78.48, Difference: -0.79\n",
      "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
      "Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n",
      "Baseline f1: 0.79, New f1: 0.78, Difference: -0.00\n"
     ]
    }
   ],
   "source": [
    "compare_baseline_to_new_results(baseline_results, model_5_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dc262373-2719-4986-b4bc-d775ec5c062c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.01157027  0.0248591   0.02878048 -0.012715    0.03971538  0.0882776\n",
      "  0.02680985  0.05589838 -0.01068729 -0.00597292  0.00639323 -0.0181952\n",
      "  0.00030814  0.09105888  0.05874645 -0.03180628  0.01512474 -0.05162929\n",
      "  0.00991367 -0.06865346 -0.04209305  0.0267898   0.03011008  0.00321069\n",
      " -0.00337971 -0.04787356  0.02266719 -0.00985925 -0.04063613 -0.01292093\n",
      " -0.04666384  0.056303   -0.03949255  0.00517688  0.02495828 -0.07014441\n",
      "  0.02871508  0.04947684 -0.00633978 -0.08960193  0.02807117 -0.00808362\n",
      " -0.01360601  0.0599865  -0.10361787 -0.05195374  0.00232955 -0.0233253\n",
      " -0.03758105  0.03327729], shape=(50,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\n",
    "embed_samples = embed([sample_sentence,\n",
    "                      \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
    "\n",
    "print(embed_samples[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7b3aaad7-67e1-4078-ba40-6feacf773cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each sentence has been encoded into a 512 dimension vector\n",
    "embed_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "03471131-52a6-4779-831e-b6bd2fc09b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        input_shape=[],\n",
    "                                        dtype=tf.string,\n",
    "                                        trainable=False,\n",
    "                                        name='USE'\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1f297fed-f677-45de-9665-4f6aeb1dd320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "], name='model_6_USE')\n",
    "\n",
    "model_6.compile(loss='binary_crossentropy',\n",
    "                optimizer='Adam',\n",
    "                metrics=['accuracy']\n",
    "               )\n",
    "\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d2d2c799-034f-4fd9-90ce-5592e9fa6612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20221031-202212\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 18ms/step - loss: 0.5008 - accuracy: 0.7892 - val_loss: 0.4479 - val_accuracy: 0.7966\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.4144 - accuracy: 0.8130 - val_loss: 0.4369 - val_accuracy: 0.8058\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.3998 - accuracy: 0.8213 - val_loss: 0.4329 - val_accuracy: 0.8110\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.3925 - accuracy: 0.8260 - val_loss: 0.4289 - val_accuracy: 0.8110\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.3861 - accuracy: 0.8285 - val_loss: 0.4309 - val_accuracy: 0.8097\n"
     ]
    }
   ],
   "source": [
    "model_6_history = model_6.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
    "                                                                     \"tf_hub_sentence_encoder\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70bacc23-1316-48a8-95cd-91c4d42b444b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14633362],\n",
       "       [0.7282115 ],\n",
       "       [0.9857846 ],\n",
       "       [0.19558054],\n",
       "       [0.73329914],\n",
       "       [0.68633884],\n",
       "       [0.9806958 ],\n",
       "       [0.97386837],\n",
       "       [0.915164  ],\n",
       "       [0.08027413]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "70dfa756-7ad9-4ce4-86f5-c4408c14b36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "560091a2-986c-4b56-a91e-3b7a95901c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 80.97112860892388,\n",
       " 'precision': 0.8121889539579248,\n",
       " 'recall': 0.8097112860892388,\n",
       " 'f1': 0.8080388355180245}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_results = calculate_results(val_labels, model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "da767ccc-39de-406c-8af1-ab174764e6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 80.97, Difference: 1.71\n",
      "Baseline precision: 0.81, New precision: 0.81, Difference: 0.00\n",
      "Baseline recall: 0.79, New recall: 0.81, Difference: 0.02\n",
      "Baseline f1: 0.79, New f1: 0.81, Difference: 0.02\n"
     ]
    }
   ],
   "source": [
    "compare_baseline_to_new_results(baseline_results, model_6_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3d55f0df-3c04-48ba-a003-6518549df688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One kind of correct way (there are more) to make data subset\n",
    "# (split the already split train_sentences/train_labels)\n",
    "\n",
    "train_sentences_90_percent, train_sentences_10_percent, train_labels_90_percent, train_labels_10_percent = train_test_split(np.array(train_sentences),\n",
    "                                                                                                                            train_labels,\n",
    "                                                                                                                            test_size=0.1,\n",
    "                                                                                                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6a618bf7-9ea4-42d1-a9ca-f1ad1a4aa33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training examples: 6851\n",
      "Length of 10% training examples: 686\n"
     ]
    }
   ],
   "source": [
    "# Check length of 10 percent datasets\n",
    "print(f\"Total training examples: {len(train_sentences)}\")\n",
    "print(f\"Length of 10% training examples: {len(train_sentences_10_percent)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2212d286-c36b-4b28-a5f6-e4a0fa192776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    415\n",
       "1    271\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of targets in our subset of data \n",
    "# (this should be close to the distribution of labels in the original train_labels)\n",
    "pd.Series(train_labels_10_percent).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "876dd317-0429-449d-bb62-aeb5ca9e42e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Clone model_6 but reset weights\n",
    "model_7 = tf.keras.models.clone_model(model_6)\n",
    "\n",
    "model_7.compile(loss='binary_crossentropy',\n",
    "               optimizer='Adam',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "064733ee-292e-4bd6-ad22-a88655db5a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/10_percent_tf_hub_sentence_encoder/20221031-203032\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 3s 43ms/step - loss: 0.6716 - accuracy: 0.6603 - val_loss: 0.6526 - val_accuracy: 0.6903\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.5972 - accuracy: 0.8032 - val_loss: 0.5944 - val_accuracy: 0.7362\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.5178 - accuracy: 0.8149 - val_loss: 0.5398 - val_accuracy: 0.7638\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.4526 - accuracy: 0.8265 - val_loss: 0.5084 - val_accuracy: 0.7677\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.4093 - accuracy: 0.8382 - val_loss: 0.4915 - val_accuracy: 0.7703\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to 10% of the training data\n",
    "model_7_history = model_7.fit(x=train_sentences_10_percent,\n",
    "                              y=train_labels_10_percent,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"10_percent_tf_hub_sentence_encoder\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "47e603f8-1c4f-4e36-a678-36ded1c7f4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.03412073490814,\n",
       " 'precision': 0.7755630249535594,\n",
       " 'recall': 0.7703412073490814,\n",
       " 'f1': 0.7667059443150692}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_pred_probs = model_7.predict(val_sentences)\n",
    "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
    "model_7_results = calculate_results(val_labels, model_7_preds)\n",
    "\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "baf06b56-5cb3-401e-90d3-ff2f100e4926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 77.03, Difference: -2.23\n",
      "Baseline precision: 0.81, New precision: 0.78, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
      "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Compare to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_7_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1f6272c3-13e7-4942-b926-d46a0c3211ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>79.265092</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_dense</th>\n",
       "      <td>78.740157</td>\n",
       "      <td>0.791492</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.784697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>75.065617</td>\n",
       "      <td>0.751008</td>\n",
       "      <td>0.750656</td>\n",
       "      <td>0.748927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gru</th>\n",
       "      <td>76.771654</td>\n",
       "      <td>0.767545</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.766793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidirectional</th>\n",
       "      <td>76.640420</td>\n",
       "      <td>0.766590</td>\n",
       "      <td>0.766404</td>\n",
       "      <td>0.765121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv1d</th>\n",
       "      <td>78.477690</td>\n",
       "      <td>0.789165</td>\n",
       "      <td>0.784777</td>\n",
       "      <td>0.781896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_sentence_encoder</th>\n",
       "      <td>80.971129</td>\n",
       "      <td>0.812189</td>\n",
       "      <td>0.809711</td>\n",
       "      <td>0.808039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_10_percent_data</th>\n",
       "      <td>77.034121</td>\n",
       "      <td>0.775563</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.766706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          accuracy  precision    recall        f1\n",
       "baseline                 79.265092   0.811139  0.792651  0.786219\n",
       "simple_dense             78.740157   0.791492  0.787402  0.784697\n",
       "lstm                     75.065617   0.751008  0.750656  0.748927\n",
       "gru                      76.771654   0.767545  0.767717  0.766793\n",
       "bidirectional            76.640420   0.766590  0.766404  0.765121\n",
       "conv1d                   78.477690   0.789165  0.784777  0.781896\n",
       "tf_hub_sentence_encoder  80.971129   0.812189  0.809711  0.808039\n",
       "tf_hub_10_percent_data   77.034121   0.775563  0.770341  0.766706"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
    "                                  \"simple_dense\": model_1_results,\n",
    "                                  \"lstm\": model_2_results,\n",
    "                                  \"gru\": model_3_results,\n",
    "                                  \"bidirectional\": model_4_results,\n",
    "                                  \"conv1d\": model_5_results,\n",
    "                                  \"tf_hub_sentence_encoder\": model_6_results,\n",
    "                                  \"tf_hub_10_percent_data\": model_7_results})\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e1ba3970-4376-445f-b524-50576f2abc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_model_results['accuracy'] = all_model_results['accuracy'] / 100\n",
    "all_model_results.plot(kind='bar', figsize=(12, 9)).legend(bbox_to_anchor=(1.0, 1.0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "04015cac-3186-48fc-bf03-568945a91282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort model results by f1-score\n",
    "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(12, 9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "57e4a2b3-0494-451a-b959-4c456f66aee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get mean pred probs for 3 models\n",
    "baseline_pred_probs = np.max(model_0.predict_proba(val_sentences), axis=1) # get the prediction probabilities from baseline model\n",
    "combined_pred_probs = baseline_pred_probs + tf.squeeze(model_2_pred_probs, axis=1) + tf.squeeze(model_6_pred_probs)\n",
    "combined_preds = tf.round(combined_pred_probs/3) # average and round the prediction probabilities to get prediction classes\n",
    "combined_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a2e65e87-53a4-4908-9416-6bd1d607cb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.08398950131233,\n",
       " 'precision': 0.7805216999297674,\n",
       " 'recall': 0.7808398950131233,\n",
       " 'f1': 0.7805169025578647}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results from averaging the prediction probabilities\n",
    "ensemble_results = calculate_results(val_labels, combined_preds)\n",
    "ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6192d5eb-ee74-4659-82ac-f52f9a530f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our combined model's results to the results DataFrame\n",
    "all_model_results.loc[\"ensemble_results\"] = ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7b150b08-cf01-470b-b185-746c098bca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the accuracy to the same scale as the rest of the results\n",
    "all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "59e34239-e8c8-46c8-bcfb-2868331f9df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_dense</th>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.791492</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.784697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>0.750656</td>\n",
       "      <td>0.751008</td>\n",
       "      <td>0.750656</td>\n",
       "      <td>0.748927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gru</th>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.767545</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.766793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidirectional</th>\n",
       "      <td>0.766404</td>\n",
       "      <td>0.766590</td>\n",
       "      <td>0.766404</td>\n",
       "      <td>0.765121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv1d</th>\n",
       "      <td>0.784777</td>\n",
       "      <td>0.789165</td>\n",
       "      <td>0.784777</td>\n",
       "      <td>0.781896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_sentence_encoder</th>\n",
       "      <td>0.809711</td>\n",
       "      <td>0.812189</td>\n",
       "      <td>0.809711</td>\n",
       "      <td>0.808039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_10_percent_data</th>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.775563</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.766706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_results</th>\n",
       "      <td>0.780840</td>\n",
       "      <td>0.780522</td>\n",
       "      <td>0.780840</td>\n",
       "      <td>0.780517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         accuracy  precision    recall        f1\n",
       "baseline                 0.792651   0.811139  0.792651  0.786219\n",
       "simple_dense             0.787402   0.791492  0.787402  0.784697\n",
       "lstm                     0.750656   0.751008  0.750656  0.748927\n",
       "gru                      0.767717   0.767545  0.767717  0.766793\n",
       "bidirectional            0.766404   0.766590  0.766404  0.765121\n",
       "conv1d                   0.784777   0.789165  0.784777  0.781896\n",
       "tf_hub_sentence_encoder  0.809711   0.812189  0.809711  0.808039\n",
       "tf_hub_10_percent_data   0.770341   0.775563  0.770341  0.766706\n",
       "ensemble_results         0.780840   0.780522  0.780840  0.780517"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a96ede02-d3f3-4807-b3b3-d66c84ee951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save TF Hub Sentence Encoder model to HDF5 format\n",
    "model_6.save(\"model_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "00c13f1b-2d31-4721-a71e-19bdae36045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with custom Hub Layer (required with HDF5 format)\n",
    "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\", \n",
    "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fa63505d-7049-4646-b0d6-dddeb3311511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 23ms/step - loss: 0.4309 - accuracy: 0.8097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4309254586696625, 0.8097112774848938]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does our loaded model perform?\n",
    "loaded_model_6.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "55af9463-5bd3-4cd7-bbf4-9818da56b5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6_SavedModel_format\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6_SavedModel_format\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save TF Hub Sentence Encoder model to SavedModel format (default)\n",
    "model_6.save(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4db728a1-0d35-4013-a6d9-3dbea507203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TF Hub Sentence Encoder SavedModel\n",
    "loaded_model_6_SavedModel = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7f5e9fef-edfa-4023-9d4c-56564b0b2b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 17ms/step - loss: 0.4309 - accuracy: 0.8097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4309254288673401, 0.8097112774848938]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate loaded SavedModel format\n",
    "loaded_model_6_SavedModel.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4021c3d-ff66-4ed9-8ef1-a5d29ca582f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
